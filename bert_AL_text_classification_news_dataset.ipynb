{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_AL_text_classification_news_dataset.ipynb ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90fe2723a1f04b0f9de22e3ba6d48c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27e784fc3767487884a1cbeb81f844a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18cebe23579b4b04b2ba9b4161592a17",
              "IPY_MODEL_55e945c835454115aca1db49df7faa0a"
            ]
          }
        },
        "27e784fc3767487884a1cbeb81f844a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18cebe23579b4b04b2ba9b4161592a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7baf9842f8041a6912247e3302e2b61",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1233088,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1233088,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef4b267522fe4383acc7ab4f2ede8f3e"
          }
        },
        "55e945c835454115aca1db49df7faa0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6dba507673548858af174128480af5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.23M/1.23M [00:01&lt;00:00, 618kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3bf2e2bbfdb4b549c4399fe7d94d49f"
          }
        },
        "e7baf9842f8041a6912247e3302e2b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef4b267522fe4383acc7ab4f2ede8f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6dba507673548858af174128480af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3bf2e2bbfdb4b549c4399fe7d94d49f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "377226aa8d1a49348b56693c4665b7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3287f4f2d404703bda1de4abf31852f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_651675ef66e44626b13ff5376bcbf120",
              "IPY_MODEL_9dca1a1f4b5844dd95d872b90e460954"
            ]
          }
        },
        "c3287f4f2d404703bda1de4abf31852f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "651675ef66e44626b13ff5376bcbf120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2990a3307d1b49c9a26ad9ff77070172",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8218a204e77048a4a1231a77cfdc4f74"
          }
        },
        "9dca1a1f4b5844dd95d872b90e460954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0f3e959e83a4eea9cd873a27712d2bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59.0/59.0 [00:00&lt;00:00, 146B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dbf4ef6cb0a4a048c5e20a1ca4ec0a3"
          }
        },
        "2990a3307d1b49c9a26ad9ff77070172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8218a204e77048a4a1231a77cfdc4f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0f3e959e83a4eea9cd873a27712d2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dbf4ef6cb0a4a048c5e20a1ca4ec0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e68d39c4fc746958151aba4b78ba7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c817c6d08ef64e71a037b8a943c4ebb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbbe11e34ab94e5a80cd8fd6134ce85d",
              "IPY_MODEL_193317ae69464eaa943168deeb92e469"
            ]
          }
        },
        "c817c6d08ef64e71a037b8a943c4ebb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbbe11e34ab94e5a80cd8fd6134ce85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2785541286724a9b8b7fb8978353baad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 386,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 386,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f29eec7d6e054d6cbaf1c933abcc3b42"
          }
        },
        "193317ae69464eaa943168deeb92e469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db210b8aa17b4e7b85ece557cf928427",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 386/386 [00:00&lt;00:00, 1.17kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44c2e5143dfb4637896a4c49e0079601"
          }
        },
        "2785541286724a9b8b7fb8978353baad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f29eec7d6e054d6cbaf1c933abcc3b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db210b8aa17b4e7b85ece557cf928427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44c2e5143dfb4637896a4c49e0079601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8445e6a5ed04d8c8cae46ba204c2024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccdbcc4758d0495dac3f035eed73972d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_403a8f684b044a7487a4c921bc5b3a1c",
              "IPY_MODEL_b981e0e3a3624f3cb3fc77a7886c4c97"
            ]
          }
        },
        "ccdbcc4758d0495dac3f035eed73972d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "403a8f684b044a7487a4c921bc5b3a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c7a06b737b44576b0c98c2e67e3117d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 740314769,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 740314769,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7564cf3f24fe415aba4ff0cee6ba97f2"
          }
        },
        "b981e0e3a3624f3cb3fc77a7886c4c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94ef0bfa92dd49edb34a96b306154e18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 740M/740M [00:14&lt;00:00, 51.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8df112bb49b4a05ae1991b5eabf1fb6"
          }
        },
        "8c7a06b737b44576b0c98c2e67e3117d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7564cf3f24fe415aba4ff0cee6ba97f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94ef0bfa92dd49edb34a96b306154e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8df112bb49b4a05ae1991b5eabf1fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDzGVoD6TVwE",
        "outputId": "e8cd059d-8567-43e1-fd4c-422136148706"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import datetime\n",
        "import random\n",
        "import scipy.spatial as sp\n",
        "from typing import List\n",
        "import tensorflow_hub as hub\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 57.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRMvEE9TzPy",
        "outputId": "4deb6be0-e712-4581-95f5-4caa8eb227a1"
      },
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10RQvWuET6UX"
      },
      "source": [
        "**READ DATASET (DATASET -2)** Kaynak:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwZv1maO2pz_",
        "outputId": "a96d96cb-09e1-4d21-baaa-b8bcaf8cf22a"
      },
      "source": [
        "!unzip /content/drive/MyDrive/hesaplamalÄ±_oÌˆdev_3/7allV03.csv.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/hesaplamalÄ±_oÌˆdev_3/7allV03.csv.zip\n",
            "  inflating: 7allV03.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIOOsR_2T66x"
      },
      "source": [
        "df = pd.read_csv('/content/7allV03.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KofoU6xBUIY8",
        "outputId": "86ed3b7b-1243-439f-a2a6-178da2478123"
      },
      "source": [
        "df.groupby('category').size()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category\n",
              "dunya         700\n",
              "ekonomi       700\n",
              "kultur        700\n",
              "saglik        700\n",
              "siyaset       700\n",
              "spor          700\n",
              "teknoloji     700\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmtJmw9pUW71"
      },
      "source": [
        "df['encoded_categories'] = LabelEncoder().fit_transform(df['category'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnbAkaR2UX3b",
        "outputId": "ea9dc102-b0b7-4b84-cece-8d9590b3ae96"
      },
      "source": [
        "df.groupby('encoded_categories').size()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encoded_categories\n",
              "0    700\n",
              "1    700\n",
              "2    700\n",
              "3    700\n",
              "4    700\n",
              "5    700\n",
              "6    700\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut3SpaX8Hyf0"
      },
      "source": [
        "# divide train and test\n",
        "training = df.groupby('encoded_categories').apply(lambda x : x.sample(frac = 0.8))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12lqLc0aUdvZ"
      },
      "source": [
        "training_texts = training.text.values\n",
        "training_labels = training.encoded_categories.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KykxuTdWUed9"
      },
      "source": [
        "test_texts = test.text.values\n",
        "test_labels = test.encoded_categories.values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8XLK0tiUgN1"
      },
      "source": [
        "**UTILITY FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddU9gNtrUmao"
      },
      "source": [
        "def plot_histogram(data, x_label, y_label):\n",
        "  BIGGER_SIZE: int = 16\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
        "  plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title=\n",
        "  plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
        "  plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "  plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
        "  plt.rc('figure', titlesize=BIGGER_SIZE)\n",
        "  sns.set_style(\"darkgrid\")\n",
        "  p = sns.barplot(x=x_label, y=y_label, data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOVPJTJvUw3q"
      },
      "source": [
        "**BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnBuRPxUVIgu"
      },
      "source": [
        "# HyperParameters\n",
        "class HyperParameters:\n",
        "  max_len = 50\n",
        "  batch_size = 32 # data loader batch size\n",
        "  number_of_class = 7\n",
        "  epochs = 4 # training epoch number\n",
        "  lr = 5e-5 # optimizer learning rate\n",
        "  eps = 1e-8 # optimizer eps\n",
        "  seed_val = 1903"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "90fe2723a1f04b0f9de22e3ba6d48c50",
            "27e784fc3767487884a1cbeb81f844a3",
            "18cebe23579b4b04b2ba9b4161592a17",
            "55e945c835454115aca1db49df7faa0a",
            "e7baf9842f8041a6912247e3302e2b61",
            "ef4b267522fe4383acc7ab4f2ede8f3e",
            "c6dba507673548858af174128480af5a",
            "f3bf2e2bbfdb4b549c4399fe7d94d49f",
            "377226aa8d1a49348b56693c4665b7b6",
            "c3287f4f2d404703bda1de4abf31852f",
            "651675ef66e44626b13ff5376bcbf120",
            "9dca1a1f4b5844dd95d872b90e460954",
            "2990a3307d1b49c9a26ad9ff77070172",
            "8218a204e77048a4a1231a77cfdc4f74",
            "a0f3e959e83a4eea9cd873a27712d2bc",
            "5dbf4ef6cb0a4a048c5e20a1ca4ec0a3"
          ]
        },
        "id": "NWcd-3TyUqsp",
        "outputId": "5920ceae-759c-4559-cf54-68d3086d13dc"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90fe2723a1f04b0f9de22e3ba6d48c50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1233088.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "377226aa8d1a49348b56693c4665b7b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2e68d39c4fc746958151aba4b78ba7b2",
            "c817c6d08ef64e71a037b8a943c4ebb8",
            "fbbe11e34ab94e5a80cd8fd6134ce85d",
            "193317ae69464eaa943168deeb92e469",
            "2785541286724a9b8b7fb8978353baad",
            "f29eec7d6e054d6cbaf1c933abcc3b42",
            "db210b8aa17b4e7b85ece557cf928427",
            "44c2e5143dfb4637896a4c49e0079601",
            "e8445e6a5ed04d8c8cae46ba204c2024",
            "ccdbcc4758d0495dac3f035eed73972d",
            "403a8f684b044a7487a4c921bc5b3a1c",
            "b981e0e3a3624f3cb3fc77a7886c4c97",
            "8c7a06b737b44576b0c98c2e67e3117d",
            "7564cf3f24fe415aba4ff0cee6ba97f2",
            "94ef0bfa92dd49edb34a96b306154e18",
            "c8df112bb49b4a05ae1991b5eabf1fb6"
          ]
        },
        "id": "tgtYINEeVBGY",
        "outputId": "3494aefc-f56e-410e-ed22-03fce4125bfc"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
        "    num_labels = HyperParameters.number_of_class, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e68d39c4fc746958151aba4b78ba7b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=386.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8445e6a5ed04d8c8cae46ba204c2024",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=740314769.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o5ZFmCUVMGb"
      },
      "source": [
        "def prepare_data_for_bert_classification(texts: List[str], labels: List[int]):\n",
        "  \"\"\"\n",
        "  This method creates input_ids, attention_masks and labels  for BERT\n",
        "\n",
        "  Parameters:\n",
        "      texts: list of strings to get input masks\n",
        "      labels: labels of the texts in type list of integers\n",
        "\n",
        "  Returns:\n",
        "      input_ids\n",
        "      attention_masks\n",
        "      labels\n",
        "  \"\"\"\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = HyperParameters.max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "  \n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, labels"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2jL0-9BVYzS"
      },
      "source": [
        "def get_data_loader(input_ids, attention_masks, labels):\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "  dataloader = DataLoader(\n",
        "                          dataset,  \n",
        "                          sampler = RandomSampler(dataset), \n",
        "                          batch_size = HyperParameters.batch_size \n",
        "                          )\n",
        "  return dataloader\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVLRlQkVjyG"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrCXTJjPV4Wa"
      },
      "source": [
        "def fine_tune_BERT_for_classification(train_dataloader, model):\n",
        "  # resource https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "  epochs = HyperParameters.epochs\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                  lr = HyperParameters.lr,\n",
        "                  eps = HyperParameters.eps \n",
        "                )\n",
        "\n",
        "  total_steps = len(train_dataloader) * HyperParameters.epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "  seed_val = HyperParameters.seed_val\n",
        "\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "  training_stats = []\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()  \n",
        "        SequenceClassifierOutput =  model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)      \n",
        "        loss, logits = SequenceClassifierOutput.loss, SequenceClassifierOutput.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "  \n",
        "  print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "  return training_stats, model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLMdUGaWIQ0"
      },
      "source": [
        "def get_predictions(test_texts, test_labels, model):\n",
        "  model.eval()\n",
        "\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  input_ids, attention_masks, labels = prepare_data_for_bert_classification(test_texts, test_labels)\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=HyperParameters.batch_size)\n",
        "\n",
        "  for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "  return predictions, true_labels"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVfwOhC_Wc6X"
      },
      "source": [
        "class BERT:\n",
        "  def __init__(self, model):\n",
        "    self.predictions = None\n",
        "    self.model = model\n",
        "\n",
        "  def train(self, x, y):\n",
        "     training_texts = x\n",
        "     training_labels = y\n",
        "     \n",
        "     input_ids, attention_masks, labels = prepare_data_for_bert_classification(texts= training_texts, \n",
        "                                                                               labels= training_labels)\n",
        "     train_dataloader = get_data_loader(input_ids=input_ids,\n",
        "                                        attention_masks= attention_masks,\n",
        "                                        labels= labels)\n",
        "     \n",
        "     training_stats, self.model = fine_tune_BERT_for_classification(train_dataloader=train_dataloader,\n",
        "                                                                    model=self.model)\n",
        "\n",
        "     return self\n",
        "\n",
        "  def predict(self, x, y):\n",
        "    self.predictions, true_labels = get_predictions(test_texts=test_texts,\n",
        "                                                    test_labels= test_labels,\n",
        "                                                    model=self.model)\n",
        "    \n",
        "    prediction_set = []\n",
        "    for i in range(len(true_labels)):\n",
        "      # here we get the index of max probability values for each sample in one batch\n",
        "      pred_labels_i = np.argmax(self.predictions[i], axis=1).flatten()\n",
        "      prediction_set.append(pred_labels_i)\n",
        "\n",
        "    # for 32 batch we combine the predictions in one list\n",
        "    prediction_scores = [item for sublist in prediction_set for item in sublist]\n",
        "    return prediction_scores\n",
        "\n",
        "  def predict_proba(self, x, y):\n",
        "    predictions, true_labels = get_predictions(test_texts=x,\n",
        "                                               test_labels= y,\n",
        "                                               model=self.model)\n",
        "    return np.array([item for sublist in predictions for item in sublist])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfIsHU7IXTjN"
      },
      "source": [
        "**TRAIN WITH ALL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOObhO3DWscB"
      },
      "source": [
        "bert = BERT(model=model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGmhLpxEIR1E"
      },
      "source": [
        "scaler = MinMaxScaler() # initialize scaler to normalize probabilities"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jgcWkXoWt1b",
        "outputId": "ce943f1b-4b94-4dfc-831c-ace4643118ac"
      },
      "source": [
        "bert.train(training_texts, training_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.92\n",
            "Training epoch took: 0:00:23\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.24\n",
            "Training epoch took: 0:00:23\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.11\n",
            "Training epoch took: 0:00:23\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:22\n",
            "Training completed in 0:01:30 (h:mm:ss)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.BERT at 0x7fa2c80c0e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jkg3B0WWudS",
        "outputId": "77b2e48a-be64-4160-89f9-4565f4f73490"
      },
      "source": [
        "prediction_scores = bert.predict(training_texts, training_labels)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lTLXz0Ip3cR",
        "outputId": "a98ad9be-6147-4b8f-c3e9-bedeade207ac"
      },
      "source": [
        "f1_score(test_labels, prediction_scores, average=\"macro\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9298072090799337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA5xZwWuIU7h",
        "outputId": "319379c3-42ba-463c-9549-ee00040edc43"
      },
      "source": [
        "all_data_probabilities = bert.predict_proba(test_texts, test_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_wuHl0dIXT1",
        "outputId": "6fce94eb-bd48-4224-8cbf-9539cc397bd4"
      },
      "source": [
        "scaler.fit(all_data_probabilities)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvl0OBSEYpKv"
      },
      "source": [
        "**ACTIVE LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwipA8K5XMeU",
        "outputId": "665bc82f-80c6-48a1-9c4f-22a46c37d22b"
      },
      "source": [
        "training.info()\n",
        "training.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "MultiIndex: 3920 entries, (0, 1033) to (6, 4849)\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            3920 non-null   object\n",
            " 1   text                3920 non-null   object\n",
            " 2   encoded_categories  3920 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 294.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hM5oijEo8NQ",
        "outputId": "bc367668-62f3-4ef6-80c9-b50ca40bddf5"
      },
      "source": [
        "test.info()\n",
        "test.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 853 entries, 1 to 4898\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            853 non-null    object\n",
            " 1   text                853 non-null    object\n",
            " 2   encoded_categories  853 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 26.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGyXez9Yuok"
      },
      "source": [
        "label_counts = (training['category']\n",
        "                .value_counts(normalize=True)\n",
        "                .rename('percentage')\n",
        "                .mul(100)\n",
        "                .reset_index()\n",
        "                .rename(columns = {\"index\":\"label\"})\n",
        "                )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "kinDhPtaYwmC",
        "outputId": "01bee12a-e29b-46e3-c50d-c97f93a1e08f"
      },
      "source": [
        "plot_histogram(label_counts, \"label\", \"percentage\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHqCAYAAAADAefsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhsVXnv8e/xDAyCHMCDcQaivnEKRvGqURFMQMABjYCoUcEAShyDUVBkEhG8RkVBlHslAZWogYgGkVFGQaLoNSjKqyBDQIhMB5nhDPePtRvKOtV9endXd1Wv+n6ep5/u3rv2rndV7dq/Wnuct3LlSiRJUr0eMegCJEnSzDLsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyi0YdAEzZcWKFSuXL/e0QknSaFi4cP4twJJe46oN++XLV7J06T2DLkOSpFmxZMm61443zs34kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlVsw6AJm2zqPWpO11lg46DL64t77H+SuP9zXapoN1lvI/EVrzlBFs2v5A/dx2x0PTvrx66y3kLUqaTvAvQ/cx10t2r/+OgtZsFYd7V92733cftfk2w6w3qPWYtEadazyHrh/GXf84d5W06y37iIWrbnGDFU0ux64737uuPOBVtOsv95aLFhUx/u/7IFl3H5Hu/e/jpa3sNYaC3neB78y6DL64iefeit30S7s5y9ak+s+9uwZqmh2PemAnwOTX+GvtWhNXnzki2euoFl20Xsu4q4W7V+w1pqcv8XLZrCi2fOyC86HlmG/aI0FHPWBU2aootn17k+/uvU0i9Zcg0P/dscZqGb27fe1k6Bl2C9YtIBfHXrODFU0u56+38tbTzPrYR8RTwD2ATYHNgPWAjbJzGsmmGZf4DDgosx8yWzUKUlSLQaxz/4pwM7A7cCFq3twRGwKfBT4/QzXJUlSlQYR9hdk5mMyc3vgxEk8/ovACcCvZrYsSZLqNOthn5krJvvYiHgT8FzgwzNXkSRJdRvaU+8iYn3gs8CHMvO2QdcjSdJcNbRhD3wK+DVw3IDrkCRpThvKU+8i4qXAW4HnZubKqcxj/vx5LF68dn8LG0Kj0MaJ2P7Rbf8otx1sv+1v1/6hDHvgGOBY4PqIWNwMWwDMb/6/NzPvn2gGy5evZOnSe1YZvmTJuv2udaB6tXEio9z+2toOo91+l33b38YotH+iNg5r2D+9+Xlnj3G3A/8AHDGrFUmSNEcNa9hv1WPYEcB84D3AlbNbjiRJc9dAwj4ixq7Z+Lzm93YRcTNwc2aen5nn9ZhmKbCg1zhJkjS+QfXsuy+mc3Tz+3xgy9ktRZKkug0k7DNz3hSm2XIGSpEkqXrDfJ69JEnqA8NekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVWzDbTxgRTwD2ATYHNgPWAjbJzGs6HrM5sCewBfAk4BbgQuCjmXn1bNcsSdJcNoie/VOAnYHbKQHeyy7AM4HPA9sB+wLPBS6NiCfORpGSJNVi1nv2wAWZ+RiAiNgd2KbHYz6ZmTd3DoiIi4CrgT2AA2a8SkmSKjHrPfvMXDGJx9zcY9i1wM3A42eiLkmSajVnDtCLiKcDGwG/GnQtkiTNJXMi7CNiAfAlSs/+2AGXI0nSnDKIffZTcRTwl8ArM/P2yUwwf/48Fi9ee2arGgKj0MaJ2P7Rbf8otx1sv+1v1/6hD/uIOJxyGt7bMvPMyU63fPlKli69Z5XhS5as28fqBq9XGycyyu2vre0w2u132bf9bYxC+ydq41CHfUTsRzkn/z2Z+dVB1yNJ0lw0tPvsI+K9wMeB/TLzqEHXI0nSXDWQnn1E7Nj8+bzm93YRcTNwc2aeHxG7AEcApwPnRMQLOyb/Q2b+chbLlSRpThvUZvwTu/4/uvl9PrAlsC0wr/m9bddjxx4jSZImYSBhn5nzVjN+V2DXWSlGkqTKDe0+e0mS1B+GvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKrdgtp8wIp4A7ANsDmwGrAVskpnXdD1uTeAQ4G+BxcDPgH0y84JZLViSpDluED37pwA7A7cDF07wuGOBPYADgFcBNwJnRMRzZrxCSZIqMus9e+CCzHwMQETsDmzT/YCI2Ax4E/D2zPyXZtj5wOXAx4DXzF65kiTNbbPes8/MFZN42GuAB4Fvdky3DPgG8IqIWGOGypMkqTrDeoDeM4GrM/OeruGXA4souwIkSdIkDGvYb0DZp9/tto7xkiRpEgaxz35WzJ8/j8WL1x50GTNuFNo4Eds/uu0f5baD7bf97do/rGF/O/DkHsPHevS39Rj3R5YvX8nSpd17AWDJknWnV9mQ6dXGiYxy+2trO4x2+132bX8bo9D+ido4rJvxLwc2iYjury7PAB4Arpz9kiRJmpuGNexPARYCO40NiIgFwBuAMzPz/kEVJknSXDOQzfgRsWPz5/Oa39tFxM3AzZl5fmb+v4j4JnBERCwErgb2AjYB3jz7FUuSNHcNap/9iV3/H938Ph/Ysvl7N+BQ4OOUy+X+F7BtZv50NgqUJKkWAwn7zJw3icfcC+zd/EiSpCka1n32kiSpTwx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZVb0HaCiHgk8HfAFsCGwJ6Z+ZuI2AX4WWZe0ecaJUnSNLQK+4h4InAe8ATgCuBZwLrN6K2AvwZ272N9kiRpmtpuxv80cD/wNOB5wLyOcecDL+1TXZIkqU/ahv3WwIGZeS2wsmvcDcDj+1KVJEnqm7Zhvwi4c5xx6wHLpleOJEnqt7Zhfxnw+nHGbQf8ZHrlSJKkfmt7NP6ngJMiAuBfm2HPiIgdKEfov6aPtUmSpD5o1bPPzG8Bfw/sBJzdDP4K8H7g3Zl5en/LkyRJ09X6PPvM/FJEfBV4EbARcCtwcWaOty9fkiQNUOuwB8jMu3m4Zy9JkoZY24vqbDHB6BXAHcAVmfngtKqSJEl907Znfx6rnl/f7Z6I+Hxm7je1kiRJUj+1PfVuB+C/ge8Cu1JOt9sV+B5wPbAbcDzwoYj4x75VKUmSpqxtz/61wOmZ+c6u4V+NiGOArTJzt4hYQTkV75/6UaQkSZq6tj371wH/Ps64kyg9f4DTgU2mWpQkSeqftmE/H/jTccY9pRkP5WY590+1KEmS1D9tN+N/D/hERNwMfDszl0fEfEqP/1Dg1OZxzwSu6l+ZkiRpqtqG/XuAk4ETgWURcTuwfjOfi5rxUE7B+0S/ipQkSVPXKuwz8xbgpRGxDfAC4LHAjcAlmXlWx+OO72uVkiRpyqZ6Bb0zgTP7XIskSZoBbQ/QkyRJc0zrnn1E7AnsBQSwRvf4zJy/ykSSJGlg2l4b/63AkZSr5G0G/DOwkHIf+5uBE/pVWES8GDgQeA6wFvAb4KjM/Od+PYckSaOg7Wb89wOHUXr2AEdn5tuATYF7Kbe7nbaI+HPKXfUWAnsAfwP8GDg2IvaaaFpJkvTH2ob9U4ELKHe4WwEsAsjM2ynn2b+vT3XtQrlAz6sz8zuZeVZmvgO4BHhrn55DkqSR0Dbs7wUekZkrgZsoPfoxdwGP61Ndi4AHm+frdAceVChJUittD9D7OeWyuGcDFwIfiYirgWXAQcAVfarrOMqugs9HxKHAPcBOwF8Bb+nTc0iSNBLa9pL/D+WKeQD7A+sAP6BsXn8a8IF+FJWZvwC2pNxY5wbgduALwDsz8xv9eA5JkkZF2yvofbPj7ysj4pnAi4C1gYubK+xNW0Q8lXJ3vcuBd1I25+8AfCki7svM1R71P3/+PBYvXrsf5Qy1UWjjRGz/6LZ/lNsOtt/2t2t/21PvtgB+mpl3AWTm3ZRN+kTEIyNii8y8oFUFvX2Css/+VZn5YDPs+xGxIfC5iPh6Zq6YaAbLl69k6dJ7Vhm+ZMm6fShvePRq40RGuf21tR1Gu/0u+7a/jVFo/0RtbLsZ/1zgGeOM+7NmfD88G/ivjqAf8yNgQ2CjPj2PJEnVaxv28yYYtwawfBq1dLoJeE5ELOoa/gLgPuC2Pj2PJEnVW+1m/IjYmD8+xW7ziFin62FrAW8HrutTXUdRbqN7SkQcTdln/xrgjcBnM/OBPj2PJEnVm8w++7dRLlu7svk5kj/u4a9s/l8GvKsfRWXmSRGxPbAP8GVgTeCqZv7H9OM5JEkaFZMJ++OA8yiBfg4lcH/Z9Zj7gV9nZt82r2fmacBp/ZqfJEmjarVhn5nXAtcCRMRWlKPx75zpwiRJUn+0Pc/+/JkqRJIkzYy259kvAj5MOVDuSax6P/uVmdn2ErySJGkGtQ3mT1H22Z8GfIuyr16SJA2xtmG/I3BgZh46E8VIkqT+a3tRnXWAH85EIZIkaWa0DftTgC1mohBJkjQz2m7GPxL4SkSsAL5Hj8vWZuZv+1GYJEnqj7ZhP7YJ/yDKVfV6mT/laiRJUt+1Dfu3Uy6PK0mS5oi2F9U5bobqkCRJM2RKF8CJiEdQ7mu/IXBpZt7d16okSVLftD0an4h4F+V+85dRbowTzfBvR8R7+1ueJEmarlZhHxF7AJ8Dvg3szB/f6vZC4PX9K02SJPVD25793sCnM3NP4OSucVfQ9PIlSdLwaBv2mwBnjDPubmDx9MqRJEn91jbsbwE2HmdcADdMqxpJktR3bcP+u8ABEbFpx7CVEfFo4B8o+/IlSdIQaRv2H6Xc1vYXwNmUC+x8HvgVsBz4WF+rkyRJ09Yq7DPzFmBz4DBgIXAV5Vz9o4AXZeYdfa9QkiRNS+uL6mTmncAhzY8kSRpybc+zf1pEvGyccVtExFP7U5YkSeqXtvvsjwBePc64VwGfnV45kiSp39qG/ebABeOMuwB4/vTKkSRJ/dY27NcF7htn3IPAetMrR5Ik9VvbsP8t8FfjjHs5cM20qpEkSX3X9mj8rwCHRMR1wJcz8/6IWAPYHXg/cFCf65MkSdPUNuz/ibJf/kjgcxFxG7ABZQvBvwOf7G95kiRpulqFfWYuB3aMiJcDWwMbUq6Xf2Zmntf/8iRJ0nRNOuwjYhFwCbBvZp4JnDNjVUmSpL6Z9AF6mfkA5Ra3y2auHEmS1G9tj8Y/C9hmJgqRJEkzo+0BekcCX4uIBZTb2d5IufPdQzLzt32qTZIk9UHbsD+/+b035f71vcyfejmSJKnf2ob9bjNShSRJmjFtT707fqYKkSRJM6P1/ewBIuIRwDMo59lfmpl397UqSZLUN22Pxici3gXcBFxGOdc+muHfjoj39rc8SZI0Xa3CPiL2AD5HORJ/Z2Bex+gLgdf3rzRJktQPbXv2ewOfzsw9gZO7xl1B08uXJEnDo23YbwKcMc64u4HF0ytHkiT1W9uwvwXYeJxxAdwwrWokSVLftQ377wIHRMSmHcNWRsSjKRfZ+XbfKpMkSX3RNuw/CtwP/AI4uxn2eeBXwHLgY/0rTZIk9UOrsM/MW4DNgcOAhcCVlHP1jwJelJl39L1CSZI0La0vqpOZd0bE54DvA4+n7Kf/eWbe2e/iACJie2Bf4LnACuDXwIcy85yZeD5JkmozlYvqHAD8N+W8+m80v6+PiI/2uTYi4h3Ad4CfAK8DdgJOBNbu93NJklSrVj37iDgY2B/4MiXo/wd4DPBG4OCIWJCZB/WjsIjYGDgC+GBmHtExarxT/yRJUg9tN+PvQbmozgc7hl0OnBMRdwB7Agf1qba3Uzbbf6lP85MkaSS13Yy/HuP3rE9vxvfLSyhX5dslIq6KiGURcWVzbX5JkjRJbcP+P4HnjzPu+c34fnkc8FTgU8DhwDbAWcBREfG+Pj6PJElVa7sZ/73AyRGxjHKg3Ng++50pm913aG5/C0BmrphGbY8A1gV2zcxvNcPOafblfzgiPp+ZK8ebeP78eSxeXP9xfKPQxonY/tFt/yi3HWy/7W/X/rZhf1nz+/Dmp9M84Ocd/6+cwvw73Urp2Z/VNfxMYFvgscDvxpt4+fKVLF16zyrDlyxZdxolDZ9ebZzIKLe/trbDaLffZd/2tzEK7Z+ojW3D+GOUEJ8NlwMvnGD8dLYaSJI0MlqFfb9Oq5ukk4G/A14BnNQxfFvg+sy8aRZrkSRpzprOZvaZ9j3gXOCY5kY7v6VcVGcbYLdBFiZJ0lzS+gp6s6U5+O61lIv3HEy5494LgDdn5nEDLE2SpDllmHv2ZOYfgHc1P5IkaQqGtmcvSZL6w7CXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLl5kzYR8TpEbEyIj4+6FokSZpL5kTYR8Qbgc0GXYckSXPR0Id9RKwPfBbYe9C1SJI0Fw192AOfBH6RmV8fdCGSJM1FCwZdwEQi4iXAW3ETviRJUza0PfuIWAQcA/xTZuag65Ekaa4a5p79h4C1gEOnMvH8+fNYvHjt/lY0hEahjROx/aPb/lFuO9h+29+u/UMZ9hHxJGA/YHdgjYhYo2P0GhGxGLgzM5ePN4/ly1eydOk9qwxfsmTdfpc7UL3aOJFRbn9tbYfRbr/Lvu1vYxTaP1Ebh3Uz/qbAmsDXgNs7fgD+sfn72YMpTZKkuWUoe/bAz4Ctegw/l/IF4FjgylmtSJKkOWoowz4zlwLndQ+PCIBrM3OVcZIkqbdh3YwvSZL6ZCh79uPJzHmDrkGSpLnGnr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVLkFgy5gPBGxI/BGYHNgI+A64FvAJzLzzkHWJknSXDLMPft/BJYDHwG2Bb4I7AWcFRHDXLckSUNlaHv2wKsz8+aO/8+PiNuA44EtgXMGUpUkSXPM0PaQu4J+zI+b34+fzVokSZrLhjbsx/Gy5vevBlqFJElzyJwJ+4h4PPAx4OzMvHTQ9UiSNFcM8z77h0TEOsB3gGXAbpOZZv78eSxevPaM1jUMRqGNE7H9o9v+UW472H7b3679Qx/2EbEWcAqwKfCyzLx+MtMtX76SpUvvWWX4kiXr9rfAAevVxomMcvtrazuMdvtd9m1/G6PQ/onaONRhHxELgZMo59pvnZk/H3BJkiTNOUMb9s259CcALwdelZmXDLgkSZLmpKENe+ALwE7AocDdEfHCjnHXT3ZzviRJo26Yj8bfrvm9H/DDrp/dB1WUJElzzdD27DNz40HXIElSDYa5Zy9JkvrAsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUMe0mSKmfYS5JUOcNekqTKGfaSJFXOsJckqXKGvSRJlTPsJUmqnGEvSVLlDHtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIqZ9hLklQ5w16SpMoZ9pIkVc6wlySpcoa9JEmVM+wlSaqcYS9JUuUWDLqA8UTEE4HPAlsD84Czgfdn5nUDLUySpDlmKHv2EbE2cA7wZ8DbgLcATwXOjYhHDrI2SZLmmmHt2e8BbApEZl4JEBGXAb8B3gF8ZoC1SZI0pwxlzx54DXDJWNADZObVwEXADgOrSpKkOWhYw/6ZwC96DL8ceMYs1yJJ0pw2rGG/AXB7j+G3AevPci2SJM1p81auXDnoGlYREQ8An8nMfbuGfxzYNzMnc6zBzcC1M1GfJElD6MnAkl4jhvUAvdvp3YMfr8ffS88GS5I0aoZ1M/7llP323Z4B/HKWa5EkaU4b1rD/D+CFEbHp2ICI2Bh4cTNOkiRN0rDus38k8F/AvcBHgZXAIcC6wJ9n5l0DLE+SpDllKHv2mXk38HLg18BXgROAq4GXG/SSJLUzlD17SZLUP0PZs59tEXFeRJw36DqmKiJeGxF7T2P6XSNiZUQ8pZ91TeJ5V0bEQVOY7o/er4jYspnXlpOY9qDmsdM+E6Xjddu4a/4vn+68Z0Ob122QIuI5zeu6wTTnc1xEXN+vuobF2DI96Dq6RcTGzfK1a8ew4yLimh6P2X0AJY4Uw74OrwWmHPZz0N83P2N+Cryo+T1oB1J2Qc0Fw/S6TeQ5lNd1WmFfsS9T3se54BDgdYMuYhQN63n20rgy85dd//8BuGRA5cy4iFgjM+/v93xrf91GRWZeD8yJLRaZedWgaxhGM/UZ7zRyYR8RuwAHAZsAV1KO9u9+zK7AvwCbZOY1HcMPAg7MzHkdw1YChwK/B/4BeDSlp/T3mXl585gjgZ2BJ2Tmgx3Trgv8DvhCZu4bEWsChwFbAxsDdwE/Bj6YmVeM057jKLcBpmNT3rWZuXEzbAnl2/Srm9quplyd8P+s5nXaHDiVcvOhN2XmfZNpazPtPOD9wDspr/OtwL8DH2kCZqLn3ZbSi3sO8ABwLrBPZmbHY84DyMwtm/+3bB63VWaeN9H8J3jOk4DjgPdSbq/80Pw7HncNcF5m7jrOfMZe//0iYr/m74Mz86DumsebZ8ey9zLgPZRl4RrK69G2XU8DPkk5ZfVRlPftP4E3Zuay7tet38tpRPxJ8/xbAxtSLnf9E+Dtmfn75jFrU97vnYHHAzdQeqqHZeaKjtcD4DcRMTb77s/mZpTl/KXAmpTlct/MvHA1r9FuwDHAAZl5eEQsbOr5W+BxTbu/RnkfH2ym2ZjyOXpnU/MewFrAhcBeTfiOzb/N/PaiXAFtN+CRwHeAPZvpvkB5H28CDsnM4zue4yC61kvjtHV1y8Ok1z8R8dfAp4CnU75oHA68BNhybN0zTg3HTeIxj6asex4FvCIzr5uoXdPV4nOyI2U9ugMwHzgFeG9m3toxr0cBnwD+hrLMXwN8CTgiM1c2jxmb3+uB7ShbZhcCi2eynSO1Gb9ZQP+Vcqvcv6EsrJ8DYqLpJuFvgVcC76N8UJ8EfKdjv/AXgY1YdfPVmygf6mOa/9egnF748WZ+e1FWXD9sVpy9HAJ8j3J54Bc1P6+Dhxa8HwDbU77gvJKygH4xIt4zXmMiYhvKwngysFNm3teirVC+EHwGOIvy4fjfwK7AqREx7jLXhO6plJXMG5r2Pwv4QUQ8frzppiMi3kq5dsPhmfnuzFwxjdmNbUo9joffiy9PcV5jZ6DsCOy7mseO51RKGO0FvKKZz/2M/7nv93L6Vcpr8EFKgLyXEgxrAzTLzBnA7pTP4XaU12t/ymdzrA0fb/7eiYdf1xvHniQingtcTNnMvwdlJXorcHZEPG+8FyciPtK0ac/MPLwZfDzldfoK8CrKe7lPM7zbh4GnAG+nfB5eRAnyTm3n9zjKl/cDKJ+BL1E+h6dS3pfLgH+JiF4XHVud1S0Pk3pfI+IZPPw53QX4SNP+ae++ar74XEQ53folMx30jcl+To5o6nojsB/l7qwnjY1s1m2nUtaLn6as+06nrAsP7fG8RwLzgLdQ1o8zatR69gcDVwA7jK3UI+IK4IdATjThajwIvKrjmzrAicD/Ai7OzF9GxPnAO4B/65juHcCZze17ycw7KCs+mvnMp6wM/4eygH22+4kz86qIuBl4IDO7N8m+j9JTeHZm/qYZdnZELAYOjIgvZuayzgki4s2UntRhmXlg27Y2B1F9ADg+M9/dTHNGU+NXKSu88S6M9HHgt8B2Y3VFxA8pp2B+gD4flxARH6J8CPfKzKmG8kMy85Lm9bihx3vR1kmZ+aGpTtz0jp5CWdY7X+9/HW+aGVhOX0TZmnNCx7xO7Pj7jZTe4Msy84Jm2Peb1/DAiPhkZv4+IsY2/f6s87bXHT4FXEc5NfeBpqYzKHfO3J/Sc3pIs1L+HCWkX8/gULEAAAtzSURBVJeZpzbDn9XUdHBmHtQ8/MyIWAYcEhGHZ+ZlHbO6JjPf1DHfJcCnIuJxmfm7Kczvqsx8W/P3GRHxUkoQvCUzv9Y8x6WUkNmRcqXRSZnM8tDiff0o8AdKr/ue5rEXUr6c3jTZmnrUuBlwGvAzYMexec+klp+TyzNzt+bv0yPiNuBrEfFXmfl9SqfqJcBumXlc87gzo1w35gMR8ZnMvKVjfj/KzFk7MHFkevbNgvt8ykr0od5bs1K+ZpqzP6tzsyfw8+b3kzqGHQ1sFRFPbep5PvAXPNxbGqtz54j4z4hYCiwD7gbWYWpbH7albI66OiIWjP1QPsAbsurtgt9P6Xm8b5ygh9W39YXAIlbt4XyD0p6X9Zpp84F4LvDNzi8gTcBcNN500/BZype/HfsR9DPg5GlOfyvli9PhEbHH2HI3Cf1cTn8MfDAi3hcRz25273TalnKzqou7ls8zKZs1X7i6YiNiLcqycSKwomMe84CzgS26JllAWRbfBPz1WNA3xh7bveyO/d+9DH6v6//uz0Lb+Z3W9f/YpvMzxgZk5u2UzcxPpJ1JLQ+TfF9fCHyvM4wz80bK1pWp2gI4n/KevWY2gr7R5nPyb13/nwis4OEtels0/3d/UfgaZZ3YfRDldD/jrYxM2FP2Ly+kfEvt1mtYG7d1/T92oMWaHcNOpnzrfUfz/zsp++9OGXtARLwa+CbwK8rK6AWULyg3d81rsjaiLIAPdv2M9a427Hr8LpR9pv8+wTxX19axI6Zv7HxQE+C3Mv4R1etTVtA39hh30wTTTdUbKT2/s/s8337p9TpMWrN/cGvgUsp+2F9HxG8jYq/VTNrP5fQNlK04H6Jsfr4hIg7o2JWzEWXLU/fy+aNmfPfy2csGlP2n+/eYz7uB9bt2HT2Kson64o7n6ZwXrPra39Q1fsyUPgsTzK/7Jl8PTDC81fpgMstDi/f1sZQvHN2msx7dnvKl4pjurY0zqeXn5H+6pn2A8t6M7WLcALhtbOtSh/He72l9xtsapbC/hbICeEyPcd3DxvZRL+oaPpmVT09Nb/jLwK4RsRElWI/tWrB3Aa7MzF0z83uZ+SPKZYOnGnS3UlZqzx/n59Kux7+essI6b4JjBFZnbAX4R9M3va0NWXUFOeZ2yv6wXs/7JxNMN1V/RemBnRYR63SNu49V33uY3heOtvOc9nnTmfnbzHwr5Q6Qf0E58PDoiNhugmn6tpxm5u8z812Z+XjgzyhbjQ7m4S8St1I2/Y63fJ7C6i2l9KaOHG8+Xcdh3EYJ+62Af+061qTnstvxf9tlsN/zm5ZJLA+TXf/cSPmi1q3XunWy9qe836dFxIunMZ/WWnxO/qh9EbGI0km5oRl0G7BBM7zTeO/3rF4bYWTCPjOXUzYr7tj5TT8iXkA58rTTtc3vZ3U8bgGwzTTLOIZyxOWJlINh/m/X+LUpm846vYXSc5nI/ZSjgbudTlnJXpeZl/b4ubPr8TcAW1KWi3Mj4rGra1APl1B6Hrt0DX8DZRPqeb0mynKJ5J8AOzW7XACIiCcDfznedNNwOaWtT2XVwL8WeFrnhzYitqAcvLQ6D9D7vZjOPKclM1dm5s94+JiHZ030eGZgOc3iI5QvdWPPfzplc/Rd4yyfY/s3x3rMq7yuzXJzIbAZ8NNe8+kxzXmUgwG3B77eEfhjxw10L7tvbn6fN177xtHv+fXFBMvDZN/XS4Dto5xJAUCzrphOSD9IOSPjTMr+8JdOY15TMonPyc5d/+9EWVf+sPn//Ob/nboe92bKeuGHDNCoHaB3IGVh+nZEHEP5Jncwqx5U8mPgKsrBNo+grGz+nrLim7LMvCEi/oNyVO0pmfnfXQ85HXhtRHwW+C6wOeX0q6WrmfUvKd8o96L01u/LzJ9T9ku/AbiwmWdSjqr+M+ClmblDjxpvjHJqyDmUwH95Zv6uRRtvi4hPAx+OiLsp+zWfTjn47geUo1XHs38z/rsRcTRls97BwB2Uo1v7KjN/FQ+fBnNGRGzbfAH6BuWUp3+OcqrQJpQVwB2TmO0vgVdGxOmUYPtd8/pNZ56tRcSfUw5C+yblFNP5lCN+l9GcWjiefiynEbEeZRfJCZR9zw9STllan/IZpBm3G+WgvE9TepGLgD+lHIT22mbf7dh1Fd4VEcc387qsY3Pp3pRgPSMijqX0PB9NOQZkfmaucjZDZl4Y5eyP04BvRsQumfmLiPg6cFDzBeBiyn7W/YGvN5+pSev3/KZjksvDZNc/H6ccIHhGRPwTZb24P2Uz95TPZsnMB6OcGn0C5Qv49h0Hbs6Ilp+TZ0bEv1A+y0+jHNx7XnNwHpRl6QfAl5qDNS+nfKHcnXLA8y0M0Mj07AEy82zKt6wAvkU5Jej9dB2J32yy3AH4b8qmxy9QTiM7rg9ljO0vP6bHuP9LWYDeQNmktT3l9I3VBcKXKQvgJyj7IU+Bh46u/UtK4O5DOdDnnyltO3e8mWXmTZRe74OUTfptT3vbj7IC3o6y0hg79eiVOcGpbZl5OmUT62LKwTBfouw/fEmPLxx92QSWmUk5UOrJlCNnH5WZ51L2Vb+A8lruRjnlcHVfuqDsJ767me7HlIBnmvOcipsoR6jvTdlv/nXKaV2vysyfTGL66S6n91HOdd+DcnrSyZSge3Nmfgce2mXwimZ+e1KW0xMop55dTLPPOjP/i3Lq6KspK9MfN22hGf9Tyib7W4HPU75MfA54Ng/3rleRmRc1z//XwInNVpddKedcv72p5++a/982zmxWp9/zm6rJLA+TWv9kuajVKylbpf6Nco79UZQtc9P68tqse9/U1HhaRGw1nflNQpvPyfsoxxV9k7Ku/S4dvfhm3fZKymmV+1A6Lq9s5r0fA+aNcGZZRJxA2dy16UTBp/FFxE+B32bmjoOupVYup2qj2Q12JXBqZv7doOvpp46tf1s3HcY5adQ24w9MRLyQchW0NwB7uwJtLyI2pfTC/5wJzhfX1LmcajKiXG3xYsqZGo+j9HrXp2xR0RAy7GfPDylXnDqeci6z2nsv5YChE/A1nCkup5qMNSm7Ix5D2d3yI8p1Cy6bcCoNjJvxJUmq3EgdoCdJ0igy7CVJqpxhL0lS5Qx7SUC5L3pEtDqIJyI2joiVEdG3u3c18zuoX/OTZNhLklQ9w16SpMp5nr2kniLi3Tx8eelHUK5xf0jXPeDHLIqIz1AuAbwO5bri787Ma7rmuSfwrmaedwHfAT6YmbN6Bzhp1NizlzSejSn3XdiJckW9Syk3Kdq2x2M/TLmD4G6UMH8e5V4DC8ceEBGHU+4zcTblRjcfBLalXAN9dXd2lDQN9uwl9ZSZ/zj2d3P3x+9T7va1F+UOaZ3uBHYYu7xuRPyactOatwLHRsTGlHA/ODM/1jHfsce9Gvj2jDVGGnGGvaSeIuJ5lFsMP59yO+h5zajs8fCTOq+jn5kXRcT1lDvdHQtsTdmSeELH/eMB/pPyRWELDHtpxrgZX9IqIuKJlJ78BpR7mv8lJfRPp1wXvdv/jDNs7PbIGzW/r6TcOrnzZ11gw37VLmlV9uwl9bItsB6wc2ZePzYwItYe5/GPGWfYz5q/b21+bwPc3uOxt/YYJqlPDHtJvYyF+oNjAyLiaZR73F/f4/E7RsRBHfvsXww8gXIXPYCzgBXAkzLzrBmrWlJPhr2kXs4GlgFfiYhPA4+l7L+/jt67/9YFvh0Rx1D27x8G/Ab4CkBmXhURnwSOiogAzgfuA55I2Z//5cw8d2abJI0u99lLWkVmXk45x/7JwH8AHwL2BS4YZ5LDKPvjjwOOBn4KvCIzH9oykJkfAfakHIz3b5Rz7PehbNb/zUy0Q1Lh/ewlSaqcPXtJkipn2EuSVDnDXpKkyhn2kiRVzrCXJKlyhr0kSZUz7CVJqpxhL0lS5Qx7SZIq9/8BCO5bzpioQgEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyjjVRmxYy6v",
        "outputId": "6e5e965b-df92-4beb-e162-6286d351ab03"
      },
      "source": [
        "# First create initial train samples\n",
        "initial_train = training.sample(frac=0.0254, random_state=42)\n",
        "initial_train.reset_index(drop=True, inplace=True)\n",
        "initial_train.info()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            100 non-null    object\n",
            " 1   text                100 non-null    object\n",
            " 2   encoded_categories  100 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 2.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "V2-7XHSc0Lkk",
        "outputId": "c3d2dcea-b1b8-4753-cf9b-a49bcc8d6dfc"
      },
      "source": [
        "initial_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ekonomi</td>\n",
              "      <td>hollywood Â’ a rakip stÃ¼dyo kuruluyor mars_ent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kultur</td>\n",
              "      <td>bridget aÅŸkÄ± internette arÄ±yor ilerleyen yaÅŸÄ±...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spor</td>\n",
              "      <td>2013 eurobasket in maskotu aÃ§Ä±klandÄ± slovenya...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>skype geÃ§miÅŸinizi silin ! microsoft kullanÄ±cÄ±...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>saglik</td>\n",
              "      <td>Ã§ocuklarÄ±nÄ±zla ve eÅŸlerinizle Ã§ok ilgilenin k...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     category  ... encoded_categories\n",
              "0    ekonomi   ...                  1\n",
              "1     kultur   ...                  2\n",
              "2       spor   ...                  5\n",
              "3  teknoloji   ...                  6\n",
              "4     saglik   ...                  3\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5kWGovpY27k",
        "outputId": "b91e567c-3b2f-419b-ed34-fc397b2c6542"
      },
      "source": [
        "initial_train.groupby('encoded_categories').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encoded_categories\n",
              "0    15\n",
              "1    18\n",
              "2    15\n",
              "3    15\n",
              "4    11\n",
              "5    12\n",
              "6    14\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7DFWhVoY4uH"
      },
      "source": [
        "# then create unlabeled data pool\n",
        "pool = training[~training.index.isin(initial_train.index)]\n",
        "pool.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QDJzYwmRzyKt",
        "outputId": "e302e0b3-6135-4e7e-d427-5aab56b275de"
      },
      "source": [
        "pool.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>tÃ¼rkiye nin yerini mÄ±sÄ±r aldÄ± bbc tÃ¼rkiye nin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>tÃ¼rk israil iliÅŸkileri sÄ±nanÄ±yor new_york tim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>ÅŸehitlikte Ã§ekilen bu fotoÄŸraf iÅŸinden etti a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>lÃ¼bnan da Ã§atÄ±ÅŸmalar 3 Ã¶lÃ¼ lÃ¼bnan Ä±n baÅŸkenti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>yahudilerin torunlarÄ±na vatandaÅŸlÄ±k hakkÄ± isp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ... encoded_categories\n",
              "0   dunya   ...                  0\n",
              "1   dunya   ...                  0\n",
              "2   dunya   ...                  0\n",
              "3   dunya   ...                  0\n",
              "4   dunya   ...                  0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KJThHjcY6Cq"
      },
      "source": [
        "# sample selection class\n",
        "class SampleSelection:\n",
        "  def __init__(self):\n",
        "    self.scaler = scaler # normalizer to scale probas 0-1\n",
        "\n",
        "  @staticmethod\n",
        "  def random_selection(unlabeled_data: np.ndarray, num_samples: int) -> List[int]:\n",
        "    \"\"\"\n",
        "    Random selection from unlabeled data pool\n",
        "\n",
        "    Parameters:\n",
        "      num_samples: how much samples we will label in one iteration\n",
        "      unlabeled_data: samples in unlabeled pool\n",
        "\n",
        "    Returns:\n",
        "    List of data samples indexes from unlabeled dataset\n",
        "    \"\"\"\n",
        "    if unlabeled_data.shape[0] >= num_samples:\n",
        "      selection = np.random.choice(unlabeled_data.shape[0], num_samples, replace=False) # randomly choice indexes \n",
        "    else:\n",
        "      selection = np.arange(unlabeled_data.shape[0])\n",
        "    return selection\n",
        "\n",
        "  def get_hard_samples(self, class_probas: np.ndarray, num_samples:int) -> List[int]:\n",
        "    \"\"\"\n",
        "    This method takes hard sample indexes from unlabeled data pool\n",
        "\n",
        "    hard-> probability of two class is similar (diffirence is small)\n",
        "\n",
        "    Parameters:\n",
        "      class_probas: probabilities for each class for all samples\n",
        "      num_samples: how much samples we will label in one iteration\n",
        "\n",
        "    Returns:\n",
        "    List of data samples indexes from unlabeled dataset   \n",
        "    \"\"\"\n",
        "    class_probas_scaled = self.scaler.transform(class_probas) \n",
        "    differences = np.std(class_probas_scaled, axis=1) # get the varyans for each proba\n",
        "\n",
        "    if len(class_probas_scaled) >= num_samples:\n",
        "      selection = np.argsort(differences)[:num_samples] # take the sample indexes which proba for two class is very close\n",
        "    else:\n",
        "      selection = np.argsort(differences)\n",
        "    \n",
        "    return selection"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMETXjk2Y_ix"
      },
      "source": [
        "class BertActiveLearner:\n",
        "  def __init__(self, test: pd.DataFrame,\n",
        "               initial_train: pd.DataFrame,\n",
        "               pool: pd.DataFrame,\n",
        "               batch_size: int,\n",
        "               label_col_name,\n",
        "               text_col_name):\n",
        "    self.batch_size = batch_size # number of samples to add train data in each iteration\n",
        "    self.test = test\n",
        "    self.train = initial_train.copy()\n",
        "    self.pool = pool.copy()\n",
        "    self.text_col_name = text_col_name\n",
        "    self.label_col_name = label_col_name\n",
        "    self.calculated_metrics = list()\n",
        "    self.classifier = BERT(model=model)\n",
        "    self.classifier.train(x=self.train[text_col_name].values, y=self.train[label_col_name].values)\n",
        "    prediction_scores = self.classifier.predict(x=self.test[text_col_name].values,\n",
        "                                                y=self.test[label_col_name].values)\n",
        "    self.calculated_metrics.append(f1_score(self.test[label_col_name].values, prediction_scores, average=\"macro\"))\n",
        "    \n",
        "  def active_learning(self, num_iteration: int, sampling_method):\n",
        "    for i in range(num_iteration):\n",
        "      print(f\"################### ITERATION: {i + 1} ###################\")\n",
        "      probs = self.classifier.predict_proba(x=self.pool[self.text_col_name].values, y=self.pool[self.label_col_name].values)\n",
        "\n",
        "      indexes = sampling_method(probs, self.batch_size) # get the indexes of data samples\n",
        "  \n",
        "      new = self.pool[self.pool.index.isin(indexes)] # select data samples by indexes from pool\n",
        "      self.train = pd.concat([self.train, new]) # as we already have labels, append labelled sample to train data\n",
        "      self.train.reset_index(drop=True, inplace=True)\n",
        "      self.pool.drop(indexes, inplace=True) # drop selected samples from ublabeled pool\n",
        "      self.pool.reset_index(drop=True, inplace=True) # reset indexing\n",
        "      self.classifier = BERT(model=model)\n",
        "      self.classifier.train(self.train[self.text_col_name].values, self.train[self.label_col_name].values)\n",
        "      prediction_scores = self.classifier.predict(x=self.test[self.text_col_name].values,\n",
        "                                                  y=self.test[self.label_col_name].values)\n",
        "      self.calculated_metrics.append(f1_score(self.test[self.label_col_name].values, prediction_scores, average=\"macro\"))\n",
        "      print(self.calculated_metrics)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1zkfy-GmDKY"
      },
      "source": [
        "iterations_num = int(pool.shape[0]/100)\n",
        "#iterations_num = 100\n",
        "batch_size = 100"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1tX4s-FLEPG",
        "outputId": "3a22c684-4f33-4873-f388-862274344790"
      },
      "source": [
        "iterations_num"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CahFFkDQ-nnQ",
        "outputId": "9ab1d51c-5aec-40ef-e3cf-b52b2b12d3a7"
      },
      "source": [
        "# random sampling\n",
        "random_cycle = BertActiveLearner(test=test, \n",
        "                             initial_train=initial_train, \n",
        "                             pool=pool, \n",
        "                             batch_size=batch_size,\n",
        "                             label_col_name=\"encoded_categories\",\n",
        "                             text_col_name=\"text\")\n",
        "\n",
        "random_cycle.active_learning(num_iteration = iterations_num,\n",
        "                             sampling_method=SampleSelection().random_selection)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "Training completed in 0:00:02 (h:mm:ss)\n",
            "################### ITERATION: 1 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "Training completed in 0:00:05 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211]\n",
            "################### ITERATION: 2 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:07 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965]\n",
            "################### ITERATION: 3 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.08\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.08\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:09 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165]\n",
            "################### ITERATION: 4 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.07\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "Training completed in 0:00:11 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289]\n",
            "################### ITERATION: 5 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "Training completed in 0:00:14 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114]\n",
            "################### ITERATION: 6 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "Training completed in 0:00:16 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744]\n",
            "################### ITERATION: 7 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:18 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348]\n",
            "################### ITERATION: 8 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:21 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874]\n",
            "################### ITERATION: 9 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "Training completed in 0:00:23 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786]\n",
            "################### ITERATION: 10 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "Training completed in 0:00:25 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713]\n",
            "################### ITERATION: 11 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:27 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301]\n",
            "################### ITERATION: 12 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:29 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069]\n",
            "################### ITERATION: 13 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "Training completed in 0:00:32 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278]\n",
            "################### ITERATION: 14 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "Training completed in 0:00:34 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184]\n",
            "################### ITERATION: 15 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:09\n",
            "Training completed in 0:00:36 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502]\n",
            "################### ITERATION: 16 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:39 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696]\n",
            "################### ITERATION: 17 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:41 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411]\n",
            "################### ITERATION: 18 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "Training completed in 0:00:43 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722]\n",
            "################### ITERATION: 19 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "Training completed in 0:00:45 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417]\n",
            "################### ITERATION: 20 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:47 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786]\n",
            "################### ITERATION: 21 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:50 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773]\n",
            "################### ITERATION: 22 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "Training completed in 0:00:52 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331]\n",
            "################### ITERATION: 23 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:54 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947]\n",
            "################### ITERATION: 24 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:57 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926]\n",
            "################### ITERATION: 25 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:15\n",
            "Training completed in 0:00:59 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746]\n",
            "################### ITERATION: 26 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:15\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:15\n",
            "Training completed in 0:01:01 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127]\n",
            "################### ITERATION: 27 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:16\n",
            "Training completed in 0:01:03 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828]\n",
            "################### ITERATION: 28 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:16\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:16\n",
            "Training completed in 0:01:06 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283]\n",
            "################### ITERATION: 29 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:17\n",
            "Training completed in 0:01:08 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426]\n",
            "################### ITERATION: 30 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:18\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "Training completed in 0:01:10 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995]\n",
            "################### ITERATION: 31 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:18\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:18\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:18\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:18\n",
            "Training completed in 0:01:12 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816]\n",
            "################### ITERATION: 32 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:19\n",
            "Training completed in 0:01:15 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768]\n",
            "################### ITERATION: 33 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:19\n",
            "Training completed in 0:01:17 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843]\n",
            "################### ITERATION: 34 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:20\n",
            "Training completed in 0:01:19 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843, 0.9067570790087889]\n",
            "################### ITERATION: 35 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:20\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:20\n",
            "Training completed in 0:01:21 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843, 0.9067570790087889, 0.9062621512691544]\n",
            "################### ITERATION: 36 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:21\n",
            "Training completed in 0:01:23 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843, 0.9067570790087889, 0.9062621512691544, 0.9183482883625745]\n",
            "################### ITERATION: 37 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:21\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:21\n",
            "Training completed in 0:01:26 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843, 0.9067570790087889, 0.9062621512691544, 0.9183482883625745, 0.9092853387052291]\n",
            "################### ITERATION: 38 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "Training completed in 0:01:28 (h:mm:ss)\n",
            "[0.9213164589865188, 0.9267204802273211, 0.9225908900116965, 0.9118087664823165, 0.9079009323232289, 0.9156184692598114, 0.9189745366084744, 0.9138291994339348, 0.9250766788896874, 0.9052009579253786, 0.9038573598056713, 0.9190557737865301, 0.9215448431630069, 0.9285349221838278, 0.915665754099184, 0.9147773527751502, 0.914313145232696, 0.9236542949905411, 0.9085589461043722, 0.9148723400761417, 0.9129629329416786, 0.9171101066256773, 0.9135400952955331, 0.9273312726500947, 0.9149267164514926, 0.8985556111002746, 0.910484840749127, 0.9113516808000828, 0.9159924122818283, 0.9101479443813426, 0.9251603275274995, 0.9124870392279816, 0.9139099287558768, 0.9236555595648843, 0.9067570790087889, 0.9062621512691544, 0.9183482883625745, 0.9092853387052291, 0.9132715056629851]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IyUBamM-oPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7443cf-e151-43d0-feef-fb417029314f"
      },
      "source": [
        "# hard sampling\n",
        "hard_cycle = BertActiveLearner(test=test, \n",
        "                           initial_train=initial_train, \n",
        "                           pool=pool, \n",
        "                           batch_size=batch_size,\n",
        "                           label_col_name=\"encoded_categories\",\n",
        "                           text_col_name=\"text\")\n",
        "\n",
        "hard_cycle.active_learning(num_iteration = iterations_num,\n",
        "                           sampling_method=SampleSelection().get_hard_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:01\n",
            "Training completed in 0:00:02 (h:mm:ss)\n",
            "################### ITERATION: 1 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:01\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:01\n",
            "Training completed in 0:00:05 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408]\n",
            "################### ITERATION: 2 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.11\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:07 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028]\n",
            "################### ITERATION: 3 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:09 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469]\n",
            "################### ITERATION: 4 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "Training completed in 0:00:11 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829]\n",
            "################### ITERATION: 5 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:03\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:03\n",
            "Training completed in 0:00:14 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224]\n",
            "################### ITERATION: 6 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "Training completed in 0:00:16 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556]\n",
            "################### ITERATION: 7 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:04\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:18 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953]\n",
            "################### ITERATION: 8 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:20 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846]\n",
            "################### ITERATION: 9 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "Training completed in 0:00:23 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149]\n",
            "################### ITERATION: 10 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:06\n",
            "Training completed in 0:00:25 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948]\n",
            "################### ITERATION: 11 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:27 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248]\n",
            "################### ITERATION: 12 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:29 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055]\n",
            "################### ITERATION: 13 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "Training completed in 0:00:32 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843]\n",
            "################### ITERATION: 14 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:08\n",
            "Training completed in 0:00:34 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526]\n",
            "################### ITERATION: 15 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:09\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:09\n",
            "Training completed in 0:00:36 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957]\n",
            "################### ITERATION: 16 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:38 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972]\n",
            "################### ITERATION: 17 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:41 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465]\n",
            "################### ITERATION: 18 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "Training completed in 0:00:43 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258]\n",
            "################### ITERATION: 19 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:11\n",
            "Training completed in 0:00:45 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122]\n",
            "################### ITERATION: 20 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:47 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122, 0.9102960760916845]\n",
            "################### ITERATION: 21 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:50 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122, 0.9102960760916845, 0.9114457323921724]\n",
            "################### ITERATION: 22 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:13\n",
            "Training completed in 0:00:52 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122, 0.9102960760916845, 0.9114457323921724, 0.9114995942401657]\n",
            "################### ITERATION: 23 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:54 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122, 0.9102960760916845, 0.9114457323921724, 0.9114995942401657, 0.9079553372348546]\n",
            "################### ITERATION: 24 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:56 (h:mm:ss)\n",
            "[0.9142290187306935, 0.8940290467039408, 0.916639229670028, 0.9127326805142469, 0.9128348599558829, 0.9065177069381224, 0.9092462669207556, 0.9125506377788953, 0.9163778114826846, 0.9153290648593149, 0.9153989779530948, 0.9142645872329248, 0.9184200758793055, 0.917066968180843, 0.9129446552792526, 0.9129294628876957, 0.9027855777460972, 0.9105729161042465, 0.9142996968991258, 0.9124282891606122, 0.9102960760916845, 0.9114457323921724, 0.9114995942401657, 0.9079553372348546, 0.9070687728643646]\n",
            "################### ITERATION: 25 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "TP_4cTs2q0Q0",
        "outputId": "1a50e84a-13ba-4ff3-8f82-0f8ecf016fe8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BIGGER_SIZE: int = 16\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title=\n",
        "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)\n",
        "\n",
        "iterations = np.arange(0, iterations_num+1, 1)\n",
        "\n",
        "plt.title (\"F1 score on test dataset by iteration\", fontsize=BIGGER_SIZE)\n",
        "plt.ylabel(\"Test F1 score\", fontsize=BIGGER_SIZE)\n",
        "plt.ylim(0.9,1.1)\n",
        "plt.xlim(-1,iterations_num+10)\n",
        "plt.xticks(np.arange(0, iterations_num+1, 10))\n",
        "plt.yticks(np.arange(0.9,1.1,0.1))\n",
        "plt.xlabel(\"Iteration number (100  data samples per iterations)\")\n",
        "plt.plot(iterations, random_cycle.calculated_metrics, label = \"Random selection\", marker='s', markevery=10)\n",
        "plt.plot(iterations, hard_cycle.calculated_metrics, label = \"Hard sampled selection\", marker='s', markevery=10)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}