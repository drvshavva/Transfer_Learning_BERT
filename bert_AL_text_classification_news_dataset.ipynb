{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_AL_text_classification_news_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10jpgl2_288PGHT5OBB0s6y2GLJu_kOec",
      "authorship_tag": "ABX9TyPa+u1dX/5rwnp+M0d/Dc9w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c27b12f46e4243e8b771e344d962577f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ac4a3ad2604427ab59828773d448c8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5bd9e6cfc26434190e387d060b18675",
              "IPY_MODEL_a018354abbca4d1cb1bae3cfb46dff59"
            ]
          }
        },
        "8ac4a3ad2604427ab59828773d448c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5bd9e6cfc26434190e387d060b18675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5088034d0df946eda62758bd873f41e1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1233088,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1233088,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fde353403d694b58bff94c503b6f0bd1"
          }
        },
        "a018354abbca4d1cb1bae3cfb46dff59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0acae5bd46234cb786df2b212d43e444",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.23M/1.23M [00:02&lt;00:00, 614kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adfc92a832e14526ad6a386105325721"
          }
        },
        "5088034d0df946eda62758bd873f41e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fde353403d694b58bff94c503b6f0bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0acae5bd46234cb786df2b212d43e444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adfc92a832e14526ad6a386105325721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f24eb24acc8d4d9c8c42ff3d22b0bbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8345e89bf4a24337be9f3b3cbd58081d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b947429660b84c85a731540037572979",
              "IPY_MODEL_fe0c6aaee2134f6b975e7fb5e49ebcf3"
            ]
          }
        },
        "8345e89bf4a24337be9f3b3cbd58081d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b947429660b84c85a731540037572979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea280467de374562a2e805a2d7f3f946",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3084caa667b04e4c988893e486e8b5f1"
          }
        },
        "fe0c6aaee2134f6b975e7fb5e49ebcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9db2be7e420f459aacc3c3cf3e1ad1c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59.0/59.0 [00:00&lt;00:00, 148B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_977fa8ebad6b422c9add7338f5c86e50"
          }
        },
        "ea280467de374562a2e805a2d7f3f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3084caa667b04e4c988893e486e8b5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9db2be7e420f459aacc3c3cf3e1ad1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "977fa8ebad6b422c9add7338f5c86e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d66ec2bf4ee4d2c8588efdcae137f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc8bc3d6e6b9430ab5189775a5c5d2d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8975fed3015c4309aaeeadc520a03103",
              "IPY_MODEL_309655e4e50d4317b3b0364b5e843c3e"
            ]
          }
        },
        "dc8bc3d6e6b9430ab5189775a5c5d2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8975fed3015c4309aaeeadc520a03103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db4187b2fcf847858c1642caa93f4753",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 386,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 386,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27b3ba0096104acaa9ace431ff6a8a89"
          }
        },
        "309655e4e50d4317b3b0364b5e843c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e691e1dd49b4ed28fa0f1880e548151",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 386/386 [00:00&lt;00:00, 1.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01cc9816abb14e9a8f89a0c3774a4b6e"
          }
        },
        "db4187b2fcf847858c1642caa93f4753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27b3ba0096104acaa9ace431ff6a8a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e691e1dd49b4ed28fa0f1880e548151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01cc9816abb14e9a8f89a0c3774a4b6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9776b9caee354197a2fd6497de46a62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a6d888480284e719f1d796e4cfbc3ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b30952a5e65468bbf3a1009e0e47ede",
              "IPY_MODEL_1772d8faa87f4d21904e4ab8bf4cf944"
            ]
          }
        },
        "6a6d888480284e719f1d796e4cfbc3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b30952a5e65468bbf3a1009e0e47ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e7f46167be74c37bd3fff97815c9c01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 740314769,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 740314769,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69d91e89fc4041c6a015768e772899b5"
          }
        },
        "1772d8faa87f4d21904e4ab8bf4cf944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_004ae8ae0c61462599101e2de858c56f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 740M/740M [00:27&lt;00:00, 26.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c925c97347e43a2baffa498171a1dfe"
          }
        },
        "0e7f46167be74c37bd3fff97815c9c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69d91e89fc4041c6a015768e772899b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004ae8ae0c61462599101e2de858c56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c925c97347e43a2baffa498171a1dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drvshavva/Transfer_Learning_BERT/blob/main/bert_AL_text_classification_news_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDzGVoD6TVwE",
        "outputId": "23466f3a-7c62-4d1f-8a56-f0c885700d51"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import datetime\n",
        "import random\n",
        "import scipy.spatial as sp\n",
        "from typing import List\n",
        "import tensorflow_hub as hub\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRMvEE9TzPy",
        "outputId": "f2c2316d-c103-4499-bc9c-cdb9fd6da31c"
      },
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10RQvWuET6UX"
      },
      "source": [
        "**READ DATASET (DATASET -2)** Kaynak:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwZv1maO2pz_",
        "outputId": "c08a1254-42fa-4a9c-f47b-1150b59f938d"
      },
      "source": [
        "!unzip /content/drive/MyDrive/hesaplamalÄ±_oÌˆdev_3/7allV03.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/hesaplamalÄ±_oÌˆdev_3/7allV03.csv.zip\n",
            "  inflating: 7allV03.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIOOsR_2T66x"
      },
      "source": [
        "df = pd.read_csv('/content/7allV03.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KofoU6xBUIY8",
        "outputId": "c2a29ed7-5cb4-4a7d-da68-79377c394082"
      },
      "source": [
        "df.groupby('category').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category\n",
              "dunya         700\n",
              "ekonomi       700\n",
              "kultur        700\n",
              "saglik        700\n",
              "siyaset       700\n",
              "spor          700\n",
              "teknoloji     700\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmtJmw9pUW71"
      },
      "source": [
        "df['encoded_categories'] = LabelEncoder().fit_transform(df['category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnbAkaR2UX3b",
        "outputId": "03427ff0-e36f-4525-b5c4-89409f50f9af"
      },
      "source": [
        "df.groupby('encoded_categories').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encoded_categories\n",
              "0    700\n",
              "1    700\n",
              "2    700\n",
              "3    700\n",
              "4    700\n",
              "5    700\n",
              "6    700\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut3SpaX8Hyf0"
      },
      "source": [
        "# divide train and test\n",
        "training = df.groupby('encoded_categories').apply(lambda x : x.sample(frac = 0.8))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12lqLc0aUdvZ"
      },
      "source": [
        "training_texts = training.text.values\n",
        "training_labels = training.encoded_categories.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KykxuTdWUed9"
      },
      "source": [
        "test_texts = test.text.values\n",
        "test_labels = test.encoded_categories.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8XLK0tiUgN1"
      },
      "source": [
        "**UTILITY FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddU9gNtrUmao"
      },
      "source": [
        "def plot_histogram(data, x_label, y_label):\n",
        "  BIGGER_SIZE: int = 16\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
        "  plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title=\n",
        "  plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
        "  plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "  plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
        "  plt.rc('figure', titlesize=BIGGER_SIZE)\n",
        "  sns.set_style(\"darkgrid\")\n",
        "  p = sns.barplot(x=x_label, y=y_label, data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOVPJTJvUw3q"
      },
      "source": [
        "**BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnBuRPxUVIgu"
      },
      "source": [
        "# HyperParameters\n",
        "class HyperParameters:\n",
        "  max_len = 250\n",
        "  batch_size = 32 # data loader batch size\n",
        "  number_of_class = 7\n",
        "  epochs = 4 # training epoch number\n",
        "  lr = 5e-5 # optimizer learning rate\n",
        "  eps = 1e-8 # optimizer eps\n",
        "  seed_val = 1903"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c27b12f46e4243e8b771e344d962577f",
            "8ac4a3ad2604427ab59828773d448c8b",
            "d5bd9e6cfc26434190e387d060b18675",
            "a018354abbca4d1cb1bae3cfb46dff59",
            "5088034d0df946eda62758bd873f41e1",
            "fde353403d694b58bff94c503b6f0bd1",
            "0acae5bd46234cb786df2b212d43e444",
            "adfc92a832e14526ad6a386105325721",
            "f24eb24acc8d4d9c8c42ff3d22b0bbf8",
            "8345e89bf4a24337be9f3b3cbd58081d",
            "b947429660b84c85a731540037572979",
            "fe0c6aaee2134f6b975e7fb5e49ebcf3",
            "ea280467de374562a2e805a2d7f3f946",
            "3084caa667b04e4c988893e486e8b5f1",
            "9db2be7e420f459aacc3c3cf3e1ad1c6",
            "977fa8ebad6b422c9add7338f5c86e50"
          ]
        },
        "id": "NWcd-3TyUqsp",
        "outputId": "0ea1ecba-5575-422b-95ca-1363104d1985"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c27b12f46e4243e8b771e344d962577f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1233088.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f24eb24acc8d4d9c8c42ff3d22b0bbf8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d66ec2bf4ee4d2c8588efdcae137f63",
            "dc8bc3d6e6b9430ab5189775a5c5d2d0",
            "8975fed3015c4309aaeeadc520a03103",
            "309655e4e50d4317b3b0364b5e843c3e",
            "db4187b2fcf847858c1642caa93f4753",
            "27b3ba0096104acaa9ace431ff6a8a89",
            "6e691e1dd49b4ed28fa0f1880e548151",
            "01cc9816abb14e9a8f89a0c3774a4b6e",
            "9776b9caee354197a2fd6497de46a62e",
            "6a6d888480284e719f1d796e4cfbc3ad",
            "8b30952a5e65468bbf3a1009e0e47ede",
            "1772d8faa87f4d21904e4ab8bf4cf944",
            "0e7f46167be74c37bd3fff97815c9c01",
            "69d91e89fc4041c6a015768e772899b5",
            "004ae8ae0c61462599101e2de858c56f",
            "1c925c97347e43a2baffa498171a1dfe"
          ]
        },
        "id": "tgtYINEeVBGY",
        "outputId": "0d6ba732-6456-4e11-a38e-e661ff2f8411"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
        "    num_labels = HyperParameters.number_of_class, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d66ec2bf4ee4d2c8588efdcae137f63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=386.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9776b9caee354197a2fd6497de46a62e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=740314769.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o5ZFmCUVMGb"
      },
      "source": [
        "def prepare_data_for_bert_classification(texts: List[str], labels: List[int]):\n",
        "  \"\"\"\n",
        "  This method creates input_ids, attention_masks and labels  for BERT\n",
        "\n",
        "  Parameters:\n",
        "      texts: list of strings to get input masks\n",
        "      labels: labels of the texts in type list of integers\n",
        "\n",
        "  Returns:\n",
        "      input_ids\n",
        "      attention_masks\n",
        "      labels\n",
        "  \"\"\"\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = HyperParameters.max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "  \n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2jL0-9BVYzS"
      },
      "source": [
        "def get_data_loader(input_ids, attention_masks, labels):\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "  dataloader = DataLoader(\n",
        "                          dataset,  \n",
        "                          sampler = RandomSampler(dataset), \n",
        "                          batch_size = HyperParameters.batch_size \n",
        "                          )\n",
        "  return dataloader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVLRlQkVjyG"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrCXTJjPV4Wa"
      },
      "source": [
        "def fine_tune_BERT_for_classification(train_dataloader, model):\n",
        "  # resource https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "  epochs = HyperParameters.epochs\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                  lr = HyperParameters.lr,\n",
        "                  eps = HyperParameters.eps \n",
        "                )\n",
        "\n",
        "  total_steps = len(train_dataloader) * HyperParameters.epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "  seed_val = HyperParameters.seed_val\n",
        "\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "  training_stats = []\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()  \n",
        "        SequenceClassifierOutput =  model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)      \n",
        "        loss, logits = SequenceClassifierOutput.loss, SequenceClassifierOutput.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "  \n",
        "  print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "  return training_stats, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLMdUGaWIQ0"
      },
      "source": [
        "def get_predictions(test_texts, test_labels, model):\n",
        "  model.eval()\n",
        "\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  input_ids, attention_masks, labels = prepare_data_for_bert_classification(test_texts, test_labels)\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=HyperParameters.batch_size)\n",
        "\n",
        "  for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "  return predictions, true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVfwOhC_Wc6X"
      },
      "source": [
        "class BERT:\n",
        "  def __init__(self, model):\n",
        "    self.predictions = None\n",
        "    self.model = model\n",
        "\n",
        "  def train(self, x, y):\n",
        "     training_texts = x\n",
        "     training_labels = y\n",
        "     \n",
        "     input_ids, attention_masks, labels = prepare_data_for_bert_classification(texts= training_texts, \n",
        "                                                                               labels= training_labels)\n",
        "     train_dataloader = get_data_loader(input_ids=input_ids,\n",
        "                                        attention_masks= attention_masks,\n",
        "                                        labels= labels)\n",
        "     \n",
        "     training_stats, self.model = fine_tune_BERT_for_classification(train_dataloader=train_dataloader,\n",
        "                                                                    model=self.model)\n",
        "\n",
        "     return self\n",
        "\n",
        "  def predict(self, x, y):\n",
        "    self.predictions, true_labels = get_predictions(test_texts=test_texts,\n",
        "                                                    test_labels= test_labels,\n",
        "                                                    model=self.model)\n",
        "    \n",
        "    prediction_set = []\n",
        "    for i in range(len(true_labels)):\n",
        "      # here we get the index of max probability values for each sample in one batch\n",
        "      pred_labels_i = np.argmax(self.predictions[i], axis=1).flatten()\n",
        "      prediction_set.append(pred_labels_i)\n",
        "\n",
        "    # for 32 batch we combine the predictions in one list\n",
        "    prediction_scores = [item for sublist in prediction_set for item in sublist]\n",
        "    return prediction_scores\n",
        "\n",
        "  def predict_proba(self, x, y):\n",
        "    predictions, true_labels = get_predictions(test_texts=x,\n",
        "                                               test_labels= y,\n",
        "                                               model=self.model)\n",
        "    return np.array([item for sublist in predictions for item in sublist])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfIsHU7IXTjN"
      },
      "source": [
        "**TRAIN WITH ALL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOObhO3DWscB"
      },
      "source": [
        "bert = BERT(model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGmhLpxEIR1E"
      },
      "source": [
        "scaler = MinMaxScaler() # initialize scaler to normalize probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jgcWkXoWt1b",
        "outputId": "08ee14eb-e09b-4098-87ed-f4a74be5cd65"
      },
      "source": [
        "bert.train(training_texts, training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.56\n",
            "Training epoch took: 0:01:34\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.16\n",
            "Training epoch took: 0:01:34\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:01:34\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:34\n",
            "Training completed in 0:06:15 (h:mm:ss)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.BERT at 0x7f9ec42a3b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jkg3B0WWudS",
        "outputId": "d67a9710-3fe5-4f40-b394-1886ff8391d9"
      },
      "source": [
        "prediction_scores = bert.predict(training_texts, training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lTLXz0Ip3cR",
        "outputId": "dcba2130-39b0-461f-bd26-7059a6fc5ed7"
      },
      "source": [
        "f1_score(test_labels, prediction_scores, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9416038581302478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA5xZwWuIU7h",
        "outputId": "900816a0-94b0-4e82-86ff-caefbdef87b5"
      },
      "source": [
        "all_data_probabilities = bert.predict_proba(test_texts, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_wuHl0dIXT1",
        "outputId": "f32f0a50-9cc3-410f-da92-1d169e218bb2"
      },
      "source": [
        "scaler.fit(all_data_probabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvl0OBSEYpKv"
      },
      "source": [
        "**ACTIVE LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwipA8K5XMeU",
        "outputId": "4ee762dc-49a8-4300-a948-2a22a5125287"
      },
      "source": [
        "training.info()\n",
        "training.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "MultiIndex: 3920 entries, (0, 1032) to (6, 4409)\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            3920 non-null   object\n",
            " 1   text                3920 non-null   object\n",
            " 2   encoded_categories  3920 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 294.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hM5oijEo8NQ",
        "outputId": "2ef4d850-4bd0-4185-cd01-7d8b5fa00cc3"
      },
      "source": [
        "test.info()\n",
        "test.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 833 entries, 0 to 832\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            833 non-null    object\n",
            " 1   text                833 non-null    object\n",
            " 2   encoded_categories  833 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 19.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGyXez9Yuok"
      },
      "source": [
        "label_counts = (training['category']\n",
        "                .value_counts(normalize=True)\n",
        "                .rename('percentage')\n",
        "                .mul(100)\n",
        "                .reset_index()\n",
        "                .rename(columns = {\"index\":\"label\"})\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "kinDhPtaYwmC",
        "outputId": "01bee12a-e29b-46e3-c50d-c97f93a1e08f"
      },
      "source": [
        "plot_histogram(label_counts, \"label\", \"percentage\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyjjVRmxYy6v",
        "outputId": "3b7c0949-65db-48f1-b033-f7db2dd5b304"
      },
      "source": [
        "# First create initial train samples\n",
        "initial_train = training.sample(frac=0.0254, random_state=42)\n",
        "initial_train.reset_index(drop=True, inplace=True)\n",
        "initial_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   category            100 non-null    object\n",
            " 1   text                100 non-null    object\n",
            " 2   encoded_categories  100 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 2.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "V2-7XHSc0Lkk",
        "outputId": "c3d2dcea-b1b8-4753-cf9b-a49bcc8d6dfc"
      },
      "source": [
        "initial_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ekonomi</td>\n",
              "      <td>hollywood Â’ a rakip stÃ¼dyo kuruluyor mars_ent...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kultur</td>\n",
              "      <td>bridget aÅŸkÄ± internette arÄ±yor ilerleyen yaÅŸÄ±...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spor</td>\n",
              "      <td>2013 eurobasket in maskotu aÃ§Ä±klandÄ± slovenya...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>skype geÃ§miÅŸinizi silin ! microsoft kullanÄ±cÄ±...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>saglik</td>\n",
              "      <td>Ã§ocuklarÄ±nÄ±zla ve eÅŸlerinizle Ã§ok ilgilenin k...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     category  ... encoded_categories\n",
              "0    ekonomi   ...                  1\n",
              "1     kultur   ...                  2\n",
              "2       spor   ...                  5\n",
              "3  teknoloji   ...                  6\n",
              "4     saglik   ...                  3\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5kWGovpY27k",
        "outputId": "b91e567c-3b2f-419b-ed34-fc397b2c6542"
      },
      "source": [
        "initial_train.groupby('encoded_categories').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encoded_categories\n",
              "0    15\n",
              "1    18\n",
              "2    15\n",
              "3    15\n",
              "4    11\n",
              "5    12\n",
              "6    14\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7DFWhVoY4uH"
      },
      "source": [
        "# then create unlabeled data pool\n",
        "pool = training[~training.index.isin(initial_train.index)]\n",
        "pool.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QDJzYwmRzyKt",
        "outputId": "e302e0b3-6135-4e7e-d427-5aab56b275de"
      },
      "source": [
        "pool.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>tÃ¼rkiye nin yerini mÄ±sÄ±r aldÄ± bbc tÃ¼rkiye nin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>tÃ¼rk israil iliÅŸkileri sÄ±nanÄ±yor new_york tim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>ÅŸehitlikte Ã§ekilen bu fotoÄŸraf iÅŸinden etti a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>lÃ¼bnan da Ã§atÄ±ÅŸmalar 3 Ã¶lÃ¼ lÃ¼bnan Ä±n baÅŸkenti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>yahudilerin torunlarÄ±na vatandaÅŸlÄ±k hakkÄ± isp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ... encoded_categories\n",
              "0   dunya   ...                  0\n",
              "1   dunya   ...                  0\n",
              "2   dunya   ...                  0\n",
              "3   dunya   ...                  0\n",
              "4   dunya   ...                  0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KJThHjcY6Cq"
      },
      "source": [
        "# sample selection class\n",
        "class SampleSelection:\n",
        "  def __init__(self):\n",
        "    self.scaler = scaler # normalizer to scale probas 0-1\n",
        "\n",
        "  @staticmethod\n",
        "  def random_selection(unlabeled_data: np.ndarray, num_samples: int) -> List[int]:\n",
        "    \"\"\"\n",
        "    Random selection from unlabeled data pool\n",
        "\n",
        "    Parameters:\n",
        "      num_samples: how much samples we will label in one iteration\n",
        "      unlabeled_data: samples in unlabeled pool\n",
        "\n",
        "    Returns:\n",
        "    List of data samples indexes from unlabeled dataset\n",
        "    \"\"\"\n",
        "    if unlabeled_data.shape[0] >= num_samples:\n",
        "      selection = np.random.choice(unlabeled_data.shape[0], num_samples, replace=False) # randomly choice indexes \n",
        "    else:\n",
        "      selection = np.arange(unlabeled_data.shape[0])\n",
        "    return selection\n",
        "\n",
        "  def get_hard_samples(self, class_probas: np.ndarray, num_samples:int) -> List[int]:\n",
        "    \"\"\"\n",
        "    This method takes hard sample indexes from unlabeled data pool\n",
        "\n",
        "    hard-> probability of two class is similar (diffirence is small)\n",
        "\n",
        "    Parameters:\n",
        "      class_probas: probabilities for each class for all samples\n",
        "      num_samples: how much samples we will label in one iteration\n",
        "\n",
        "    Returns:\n",
        "    List of data samples indexes from unlabeled dataset   \n",
        "    \"\"\"\n",
        "    class_probas_scaled = self.scaler.transform(class_probas) \n",
        "    differences = np.std(class_probas_scaled, axis=1) # get the varyans for each proba\n",
        "\n",
        "    if len(class_probas_scaled) >= num_samples:\n",
        "      selection = np.argsort(differences)[:num_samples] # take the sample indexes which proba for two class is very close\n",
        "    else:\n",
        "      selection = np.argsort(differences)\n",
        "    \n",
        "    return selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMETXjk2Y_ix"
      },
      "source": [
        "class BertActiveLearner:\n",
        "  def __init__(self, test: pd.DataFrame,\n",
        "               initial_train: pd.DataFrame,\n",
        "               pool: pd.DataFrame,\n",
        "               batch_size: int,\n",
        "               label_col_name,\n",
        "               text_col_name):\n",
        "    self.batch_size = batch_size # number of samples to add train data in each iteration\n",
        "    self.test = test\n",
        "    self.train = initial_train.copy()\n",
        "    self.pool = pool.copy()\n",
        "    self.text_col_name = text_col_name\n",
        "    self.label_col_name = label_col_name\n",
        "    self.calculated_metrics = list()\n",
        "    self.classifier = BERT(model=model)\n",
        "    self.classifier.train(x=self.train[text_col_name].values, y=self.train[label_col_name].values)\n",
        "    prediction_scores = self.classifier.predict(x=self.test[text_col_name].values,\n",
        "                                                y=self.test[label_col_name].values)\n",
        "    self.calculated_metrics.append(f1_score(self.test[label_col_name].values, prediction_scores, average=\"macro\"))\n",
        "    \n",
        "  def active_learning(self, num_iteration: int, sampling_method):\n",
        "    for i in range(num_iteration):\n",
        "      print(f\"################### ITERATION: {i + 1} ###################\")\n",
        "      probs = self.classifier.predict_proba(x=self.pool[self.text_col_name].values, y=self.pool[self.label_col_name].values)\n",
        "\n",
        "      indexes = sampling_method(probs, self.batch_size) # get the indexes of data samples\n",
        "  \n",
        "      new = self.pool[self.pool.index.isin(indexes)] # select data samples by indexes from pool\n",
        "      self.train = pd.concat([self.train, new]) # as we already have labels, append labelled sample to train data\n",
        "      self.train.reset_index(drop=True, inplace=True)\n",
        "      self.pool.drop(indexes, inplace=True) # drop selected samples from ublabeled pool\n",
        "      self.pool.reset_index(drop=True, inplace=True) # reset indexing\n",
        "      self.classifier = BERT(model=model)\n",
        "      self.classifier.train(self.train[self.text_col_name].values, self.train[self.label_col_name].values)\n",
        "      prediction_scores = self.classifier.predict(x=self.test[self.text_col_name].values,\n",
        "                                                  y=self.test[self.label_col_name].values)\n",
        "      self.calculated_metrics.append(f1_score(self.test[self.label_col_name].values, prediction_scores, average=\"macro\"))\n",
        "      print(self.calculated_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1zkfy-GmDKY"
      },
      "source": [
        "iterations_num = int(pool.shape[0]/100)\n",
        "#iterations_num = 100\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1tX4s-FLEPG",
        "outputId": "29a4f810-6c09-4df2-faa3-5cbdbf441f7a"
      },
      "source": [
        "iterations_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CahFFkDQ-nnQ",
        "outputId": "85205a10-f7f9-41c6-d4bd-4fd6dfc90add"
      },
      "source": [
        "# random sampling\n",
        "random_cycle = BertActiveLearner(test=test, \n",
        "                             initial_train=initial_train, \n",
        "                             pool=pool, \n",
        "                             batch_size=batch_size,\n",
        "                             label_col_name=\"encoded_categories\",\n",
        "                             text_col_name=\"text\")\n",
        "\n",
        "random_cycle.active_learning(num_iteration = iterations_num,\n",
        "                             sampling_method=SampleSelection().random_selection)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:10 (h:mm:ss)\n",
            "################### ITERATION: 1 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.13\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:19 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433]\n",
            "################### ITERATION: 2 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.12\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.10\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:29 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823]\n",
            "################### ITERATION: 3 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.30\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.12\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:38 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204]\n",
            "################### ITERATION: 4 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.10\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:48 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407]\n",
            "################### ITERATION: 5 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:57 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543]\n",
            "################### ITERATION: 6 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.08\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "Training completed in 0:01:07 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274]\n",
            "################### ITERATION: 7 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "Training completed in 0:01:17 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161]\n",
            "################### ITERATION: 8 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "Training completed in 0:01:26 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236]\n",
            "################### ITERATION: 9 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "Training completed in 0:01:36 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991]\n",
            "################### ITERATION: 10 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:26\n",
            "Training completed in 0:01:45 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659]\n",
            "################### ITERATION: 11 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "Training completed in 0:01:55 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882]\n",
            "################### ITERATION: 12 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "Training completed in 0:02:04 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591]\n",
            "################### ITERATION: 13 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:34\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:33\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:33\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:33\n",
            "Training completed in 0:02:14 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842]\n",
            "################### ITERATION: 14 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:36\n",
            "Training completed in 0:02:23 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135]\n",
            "################### ITERATION: 15 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:38\n",
            "Training completed in 0:02:33 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938]\n",
            "################### ITERATION: 16 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:41\n",
            "Training completed in 0:02:43 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339]\n",
            "################### ITERATION: 17 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:43\n",
            "Training completed in 0:02:52 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898]\n",
            "################### ITERATION: 18 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:45\n",
            "Training completed in 0:03:02 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771]\n",
            "################### ITERATION: 19 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:48\n",
            "Training completed in 0:03:11 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827]\n",
            "################### ITERATION: 20 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:50\n",
            "Training completed in 0:03:21 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953]\n",
            "################### ITERATION: 21 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "Training completed in 0:03:31 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529]\n",
            "################### ITERATION: 22 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "Training completed in 0:03:40 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671]\n",
            "################### ITERATION: 23 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:57\n",
            "Training completed in 0:03:50 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432]\n",
            "################### ITERATION: 24 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "Training completed in 0:03:59 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811]\n",
            "################### ITERATION: 25 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "Training completed in 0:04:09 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761]\n",
            "################### ITERATION: 26 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:05\n",
            "Training completed in 0:04:18 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314]\n",
            "################### ITERATION: 27 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "Training completed in 0:04:28 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716]\n",
            "################### ITERATION: 28 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "Training completed in 0:04:37 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266]\n",
            "################### ITERATION: 29 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:12\n",
            "Training completed in 0:04:47 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085]\n",
            "################### ITERATION: 30 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:14\n",
            "Training completed in 0:04:56 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124]\n",
            "################### ITERATION: 31 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:16\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:16\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:16\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:16\n",
            "Training completed in 0:05:06 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736]\n",
            "################### ITERATION: 32 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:19\n",
            "Training completed in 0:05:16 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078]\n",
            "################### ITERATION: 33 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "Training completed in 0:05:25 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802]\n",
            "################### ITERATION: 34 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:24\n",
            "Training completed in 0:05:35 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802, 0.9145456258236039]\n",
            "################### ITERATION: 35 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:26\n",
            "Training completed in 0:05:44 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802, 0.9145456258236039, 0.9174274450726537]\n",
            "################### ITERATION: 36 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.04\n",
            "Training epoch took: 0:01:28\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:28\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:28\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:28\n",
            "Training completed in 0:05:54 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802, 0.9145456258236039, 0.9174274450726537, 0.9240181980977553]\n",
            "################### ITERATION: 37 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:31\n",
            "Training completed in 0:06:03 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802, 0.9145456258236039, 0.9174274450726537, 0.9240181980977553, 0.9292015119394998]\n",
            "################### ITERATION: 38 ###################\n",
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:33\n",
            "Training completed in 0:06:13 (h:mm:ss)\n",
            "[0.9182762803361951, 0.9197660537694433, 0.919008752197823, 0.9170223856811204, 0.9222541154782407, 0.9189240282341543, 0.9188181580184274, 0.9325419464191161, 0.9188881171514236, 0.9154056016329991, 0.9235868360684659, 0.9336586262385882, 0.9280129469411591, 0.9285837388525842, 0.9263292828643135, 0.9192430629648938, 0.9270333253370339, 0.9177030452674898, 0.9268867464887771, 0.928644807697827, 0.9370596880528953, 0.9290751115329529, 0.9241198104177671, 0.9257147434529432, 0.927121199326811, 0.9170661324649761, 0.9227329778791314, 0.9241308084126716, 0.9259019406060266, 0.928228291378085, 0.9248599601530124, 0.9190553356628736, 0.9205862142856078, 0.9285872967720802, 0.9145456258236039, 0.9174274450726537, 0.9240181980977553, 0.9292015119394998, 0.9322664748169359]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IyUBamM-oPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904a239a-efd8-4b36-8dcb-fd2e7d4e9be5"
      },
      "source": [
        "# hard sampling\n",
        "hard_cycle = BertActiveLearner(test=test, \n",
        "                           initial_train=initial_train, \n",
        "                           pool=pool, \n",
        "                           batch_size=batch_size,\n",
        "                           label_col_name=\"encoded_categories\",\n",
        "                           text_col_name=\"text\")\n",
        "\n",
        "hard_cycle.active_learning(num_iteration = iterations_num,\n",
        "                           sampling_method=SampleSelection().get_hard_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:02\n",
            "Training completed in 0:00:10 (h:mm:ss)\n",
            "################### ITERATION: 1 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.05\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.06\n",
            "Training epoch took: 0:00:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:05\n",
            "Training completed in 0:00:19 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642]\n",
            "################### ITERATION: 2 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:07\n",
            "Training completed in 0:00:29 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585]\n",
            "################### ITERATION: 3 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:10\n",
            "Training completed in 0:00:38 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876]\n",
            "################### ITERATION: 4 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:12\n",
            "Training completed in 0:00:48 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228]\n",
            "################### ITERATION: 5 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:14\n",
            "Training completed in 0:00:57 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371]\n",
            "################### ITERATION: 6 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:17\n",
            "Training completed in 0:01:07 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135]\n",
            "################### ITERATION: 7 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:19\n",
            "Training completed in 0:01:16 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298]\n",
            "################### ITERATION: 8 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:22\n",
            "Training completed in 0:01:26 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447]\n",
            "################### ITERATION: 9 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:24\n",
            "Training completed in 0:01:36 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264]\n",
            "################### ITERATION: 10 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:26\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:26\n",
            "Training completed in 0:01:45 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402]\n",
            "################### ITERATION: 11 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:29\n",
            "Training completed in 0:01:55 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851]\n",
            "################### ITERATION: 12 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:31\n",
            "Training completed in 0:02:04 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985]\n",
            "################### ITERATION: 13 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:33\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:00:33\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:34\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:33\n",
            "Training completed in 0:02:14 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559]\n",
            "################### ITERATION: 14 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:36\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:36\n",
            "Training completed in 0:02:23 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046]\n",
            "################### ITERATION: 15 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:38\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:38\n",
            "Training completed in 0:02:33 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302]\n",
            "################### ITERATION: 16 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:41\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:41\n",
            "Training completed in 0:02:43 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653]\n",
            "################### ITERATION: 17 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:43\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:43\n",
            "Training completed in 0:02:52 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264]\n",
            "################### ITERATION: 18 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:45\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:45\n",
            "Training completed in 0:03:02 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968]\n",
            "################### ITERATION: 19 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:48\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:48\n",
            "Training completed in 0:03:11 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518]\n",
            "################### ITERATION: 20 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:50\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:50\n",
            "Training completed in 0:03:21 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062]\n",
            "################### ITERATION: 21 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:53\n",
            "Training completed in 0:03:30 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443]\n",
            "################### ITERATION: 22 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:55\n",
            "Training completed in 0:03:40 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614]\n",
            "################### ITERATION: 23 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:57\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:00:57\n",
            "Training completed in 0:03:49 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567]\n",
            "################### ITERATION: 24 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:00\n",
            "Training completed in 0:03:59 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319]\n",
            "################### ITERATION: 25 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:02\n",
            "Training completed in 0:04:09 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655]\n",
            "################### ITERATION: 26 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:05\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:05\n",
            "Training completed in 0:04:18 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981]\n",
            "################### ITERATION: 27 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:07\n",
            "Training completed in 0:04:28 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622]\n",
            "################### ITERATION: 28 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:09\n",
            "Training completed in 0:04:37 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506]\n",
            "################### ITERATION: 29 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:12\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:12\n",
            "Training completed in 0:04:47 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564]\n",
            "################### ITERATION: 30 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:14\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:14\n",
            "Training completed in 0:04:56 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191]\n",
            "################### ITERATION: 31 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:17\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:16\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:16\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:16\n",
            "Training completed in 0:05:06 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657]\n",
            "################### ITERATION: 32 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:19\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:19\n",
            "Training completed in 0:05:16 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358]\n",
            "################### ITERATION: 33 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:21\n",
            "Training completed in 0:05:25 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604]\n",
            "################### ITERATION: 34 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.11\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:24\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:24\n",
            "Training completed in 0:05:35 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604, 0.9254670344012077]\n",
            "################### ITERATION: 35 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:26\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:26\n",
            "Training completed in 0:05:44 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604, 0.9254670344012077, 0.9267600297636008]\n",
            "################### ITERATION: 36 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:29\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:29\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:28\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:29\n",
            "Training completed in 0:05:54 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604, 0.9254670344012077, 0.9267600297636008, 0.9199846678972643]\n",
            "################### ITERATION: 37 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:31\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:31\n",
            "Training completed in 0:06:03 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604, 0.9254670344012077, 0.9267600297636008, 0.9199846678972643, 0.9259765046624641]\n",
            "################### ITERATION: 38 ###################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 2 / 4 ========\n",
            "Average training loss: 0.02\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 3 / 4 ========\n",
            "Average training loss: 0.01\n",
            "Training epoch took: 0:01:33\n",
            "======== Epoch 4 / 4 ========\n",
            "Average training loss: 0.00\n",
            "Training epoch took: 0:01:33\n",
            "Training completed in 0:06:13 (h:mm:ss)\n",
            "[0.9322664748169359, 0.9279248271167642, 0.9354551886657585, 0.9331912872404876, 0.9318710358807228, 0.9290822462380371, 0.9247841739756135, 0.9261832127253298, 0.9243764416889447, 0.929605220905264, 0.9255376329699402, 0.9307406367257851, 0.9222443800124985, 0.9339043083949559, 0.9309875593042046, 0.9345255670550302, 0.9334284560007653, 0.9315643958684264, 0.9319303355292968, 0.9339210786428518, 0.9333910224201062, 0.9311675983777443, 0.9155736387197614, 0.9241855368876567, 0.922408043816319, 0.9217010823863655, 0.9233691081955981, 0.9245435224567622, 0.9204984494344506, 0.9306997242874564, 0.9294689319393191, 0.9332101541479657, 0.9320929115489358, 0.9299565638870604, 0.9254670344012077, 0.9267600297636008, 0.9199846678972643, 0.9259765046624641, 0.9252555836857838]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "TP_4cTs2q0Q0",
        "outputId": "e236688c-b7f4-474a-ccde-e1a325e7d4b3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BIGGER_SIZE: int = 16\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title=\n",
        "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)\n",
        "\n",
        "iterations = np.arange(0, iterations_num+1, 1)\n",
        "\n",
        "plt.title (\"F1 score on test dataset by iteration\", fontsize=BIGGER_SIZE)\n",
        "plt.ylabel(\"Test F1 score\", fontsize=BIGGER_SIZE)\n",
        "plt.ylim(0.9,0.95)\n",
        "plt.xlim(-1,iterations_num+5)\n",
        "plt.xticks(np.arange(0, iterations_num+1, 5))\n",
        "plt.yticks(np.arange(0.9,0.95,0.01))\n",
        "plt.xlabel(\"Iteration number\")\n",
        "plt.plot(iterations, random_cycle.calculated_metrics, label = \"Random selection\", marker='s', markevery=10)\n",
        "plt.plot(iterations, hard_cycle.calculated_metrics, label = \"Hard sampled selection\", marker='s', markevery=10)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}